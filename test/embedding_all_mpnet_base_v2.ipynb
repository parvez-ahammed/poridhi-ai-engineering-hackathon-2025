{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = os.getcwd() + \"/.cache/huggingface\"\n",
    "os.environ[\"HF_HOME\"] = PATH\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = PATH\n",
    "os.environ[\"TORCH_HOME\"] = PATH\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    PointStruct,\n",
    "    Distance,\n",
    "    VectorParams,\n",
    "    SparseVectorParams,\n",
    "    Modifier,\n",
    "    Prefetch,\n",
    "    SparseVector,\n",
    "    FusionQuery,\n",
    "    Fusion,\n",
    ")\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from BM25 import BM25\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"./trained_models/all_mpnet_base_v2\", device=DEVICE)\n",
    "\n",
    "bm25 = BM25(\n",
    "    stopwords_dir=os.path.abspath(\"./stopwords\"), languages=[\"english\", \"bengali\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"product_collection_all_mpnet_base_v2_trained\"\n",
    "client = QdrantClient(url=\"http://localhost:6333\", timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\"dense_vector\": VectorParams(size=768, distance=Distance.COSINE)},\n",
    "    sparse_vectors_config={\"sparse_vector\": SparseVectorParams(modifier=Modifier.IDF)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casio DJ-120D Plus Check &amp; Recheck Basic Calcu...</td>\n",
       "      <td>1305</td>\n",
       "      <td>None</td>\n",
       "      <td>009b7e66-ef69-49fc-87c8-9d40d53e0e33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colorful CN600 PRO 1TB M.2 NVMe SSD</td>\n",
       "      <td>7300</td>\n",
       "      <td>Capacity: 1TB\\nFlash Type: 3D NAND\\nInterface:...</td>\n",
       "      <td>7bd5da56-89e9-4b68-92e2-cd31f0578bcb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anker Soundcore Space One Foldable Over-Ear Bl...</td>\n",
       "      <td>7990</td>\n",
       "      <td>Frequency Range: 20Hz-20KHz\\nInput Jack: AUX C...</td>\n",
       "      <td>3c7d8f65-a7b7-47cd-b808-d6e8c445ca69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smart SEL-50V24K 50\" 4K Voice Control Android ...</td>\n",
       "      <td>51900</td>\n",
       "      <td>Display Type: LED\\nScreen Size: 50 Inch\\nResol...</td>\n",
       "      <td>212bc014-cec5-4bc6-ad82-2591098ab808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EZVIZ H3c 3MP Wi-Fi Smart Home Outdoor Securit...</td>\n",
       "      <td>4324</td>\n",
       "      <td>Image Sensor: 1/2.7”Progressive Scan CMOS\\nEff...</td>\n",
       "      <td>617e0e00-cfd2-4465-b46f-9537476327a4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  price  \\\n",
       "0  Casio DJ-120D Plus Check & Recheck Basic Calcu...   1305   \n",
       "1                Colorful CN600 PRO 1TB M.2 NVMe SSD   7300   \n",
       "2  Anker Soundcore Space One Foldable Over-Ear Bl...   7990   \n",
       "3  Smart SEL-50V24K 50\" 4K Voice Control Android ...  51900   \n",
       "4  EZVIZ H3c 3MP Wi-Fi Smart Home Outdoor Securit...   4324   \n",
       "\n",
       "                                         description  \\\n",
       "0                                               None   \n",
       "1  Capacity: 1TB\\nFlash Type: 3D NAND\\nInterface:...   \n",
       "2  Frequency Range: 20Hz-20KHz\\nInput Jack: AUX C...   \n",
       "3  Display Type: LED\\nScreen Size: 50 Inch\\nResol...   \n",
       "4  Image Sensor: 1/2.7”Progressive Scan CMOS\\nEff...   \n",
       "\n",
       "                                     id  \n",
       "0  009b7e66-ef69-49fc-87c8-9d40d53e0e33  \n",
       "1  7bd5da56-89e9-4b68-92e2-cd31f0578bcb  \n",
       "2  3c7d8f65-a7b7-47cd-b808-d6e8c445ca69  \n",
       "3  212bc014-cec5-4bc6-ad82-2591098ab808  \n",
       "4  617e0e00-cfd2-4465-b46f-9537476327a4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_info_df = pd.read_csv(\"./datasets/final_5000_products.csv\")\n",
    "product_info_df = product_info_df.replace(np.nan, None)\n",
    "product_info_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_product_details(name, price, description):\n",
    "    product_details = \"\"\n",
    "    if description is not None:\n",
    "        product_details = f\"Name: {name}\\nPrice: {price} taka\\n{description}\"\n",
    "    else:\n",
    "        product_details = f\"Name: {name}\\nPrice: {price} taka\"\n",
    "\n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row = product_info_df.shape[0]\n",
    "batch_size = 10\n",
    "total_batch = math.ceil(total_row / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in product_info_df.iterrows():\n",
    "    title = row[\"title\"]\n",
    "    description = row[\"description\"]\n",
    "    price = row[\"price\"]\n",
    "    formatted_document = format_product_details(title, price, description)\n",
    "    documents.append(formatted_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.1696\n"
     ]
    }
   ],
   "source": [
    "bm25.calculate_avg_doc_len(documents)\n",
    "print(bm25.avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b85051535c4009b5521d492f6ffebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atiqur-rahman/venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:310.)\n",
      "  return F.linear(input, self.weight, self.bias)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operation_id=499 status=<UpdateStatus.COMPLETED: 'completed'>\r"
     ]
    }
   ],
   "source": [
    "for start in tqdm(range(0, total_row, batch_size)):\n",
    "    batch = product_info_df.iloc[start : start + batch_size]\n",
    "\n",
    "    titles = batch[\"title\"].tolist()\n",
    "    descriptions = batch[\"description\"].tolist()\n",
    "    prices = batch[\"price\"].tolist()\n",
    "\n",
    "    texts_for_embedding = [\n",
    "        format_product_details(title, price, description)\n",
    "        for title, description, price in zip(titles, descriptions, prices)\n",
    "    ]\n",
    "    dense_vectors = model.encode(texts_for_embedding)\n",
    "    sparse_vectors = bm25.raw_embed(texts_for_embedding)\n",
    "\n",
    "    points = []\n",
    "    for idx, (batch_idx, row) in enumerate(batch.iterrows()):\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"description\"]\n",
    "        price = row[\"price\"]\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=batch_idx,\n",
    "                vector={\n",
    "                    \"dense_vector\": dense_vectors[idx],\n",
    "                    \"sparse_vector\": sparse_vectors[idx],\n",
    "                },\n",
    "                payload={\n",
    "                    \"title\": title,\n",
    "                    \"description\": description,\n",
    "                    \"price\": price,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    operation_info = client.upsert(\n",
    "        collection_name=COLLECTION_NAME, wait=True, points=points\n",
    "    )\n",
    "    print(operation_info, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query_text: str, query_type: str = \"hybrid\"):\n",
    "    dense_vector = model.encode([query_text])[0]\n",
    "    sparse_vector = bm25.raw_embed([query_text])[0]\n",
    "\n",
    "    prefetch = [\n",
    "        Prefetch(query=dense_vector, using=\"dense_vector\", limit=10),\n",
    "        Prefetch(query=SparseVector(**sparse_vector), using=\"sparse_vector\", limit=10),\n",
    "    ]\n",
    "\n",
    "    if query_type == \"hybrid\":\n",
    "        results = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            prefetch=prefetch,\n",
    "            query=FusionQuery(fusion=Fusion.RRF),\n",
    "            with_payload=True,\n",
    "            limit=5,\n",
    "            with_vectors=True\n",
    "        )\n",
    "\n",
    "    elif query_type == \"sparse\":\n",
    "        results = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=SparseVector(**sparse_vector),\n",
    "            using=\"sparse_vector\",\n",
    "            with_payload=True,\n",
    "            limit=5\n",
    "        )\n",
    "        \n",
    "    elif query_type == \"dense\":\n",
    "        results = client.query_points(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            query=dense_vector,\n",
    "            using=\"dense_vector\",\n",
    "            with_payload=True,\n",
    "            limit=5\n",
    "        )\n",
    "\n",
    "    return [{\"score\": point.score, \"payload\": point.payload, \"vector\": point.vector[\"dense_vector\"]} for point in results.points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = query(\"nokia\", \"hybrid\")\n",
    "pprint(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4438)\n",
      "Tecno Spark Go 1\n"
     ]
    }
   ],
   "source": [
    "dense_vector = torch.tensor(model.encode([\"nokia\"])[0])\n",
    "idx = 4\n",
    "print(torch.functional.F.cosine_similarity(dense_vector, torch.tensor(query_result[idx][\"vector\"]), 0))\n",
    "print(query_result[idx][\"payload\"][\"title\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
