{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = os.getcwd() + \"/.cache/huggingface\"\n",
    "os.environ[\"HF_HOME\"] = PATH\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = PATH\n",
    "os.environ[\"TORCH_HOME\"] = PATH\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.notebook import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    PointStruct,\n",
    "    Distance,\n",
    "    VectorParams,\n",
    "    SparseVectorParams,\n",
    "    Modifier,\n",
    "    Prefetch,\n",
    "    SparseVector,\n",
    "    FusionQuery,\n",
    "    Fusion,\n",
    ")\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from BM25 import BM25\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SentenceTransformer(\"./trained_models/all_mpnet_base_v2\", device=DEVICE)\n",
    "\n",
    "bm25 = BM25(\n",
    "    stopwords_dir=os.path.abspath(\"./stopwords\"), languages=[\"english\", \"bengali\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"product_collection_all_mpnet_base_v2_trained\"\n",
    "client = QdrantClient(url=\"http://localhost:6333\", timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(collection_name=COLLECTION_NAME)\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\"dense_vector\": VectorParams(size=768, distance=Distance.COSINE)},\n",
    "    sparse_vectors_config={\"sparse_vector\": SparseVectorParams(modifier=Modifier.IDF)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info_df = pd.read_csv(\"./datasets/final_5000_products.csv\")\n",
    "product_info_df = product_info_df.replace(np.nan, None)\n",
    "product_info_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_product_details(name, price, description):\n",
    "    product_details = \"\"\n",
    "    if description is not None:\n",
    "        product_details = f\"Name: {name}\\nPrice: {price} taka\\n{description}\"\n",
    "    else:\n",
    "        product_details = f\"Name: {name}\\nPrice: {price} taka\"\n",
    "\n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row = product_info_df.shape[0]\n",
    "batch_size = 10\n",
    "total_batch = math.ceil(total_row / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for idx, row in product_info_df.iterrows():\n",
    "    title = row[\"title\"]\n",
    "    description = row[\"description\"]\n",
    "    price = row[\"price\"]\n",
    "    formatted_document = format_product_details(title, price, description)\n",
    "    documents.append(formatted_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25.calculate_avg_doc_len(documents)\n",
    "print(bm25.avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in tqdm(range(0, total_row, batch_size)):\n",
    "    batch = product_info_df.iloc[start : start + batch_size]\n",
    "\n",
    "    titles = batch[\"title\"].tolist()\n",
    "    descriptions = batch[\"description\"].tolist()\n",
    "    prices = batch[\"price\"].tolist()\n",
    "\n",
    "    texts_for_embedding = [\n",
    "        format_product_details(title, price, description)\n",
    "        for title, description, price in zip(titles, descriptions, prices)\n",
    "    ]\n",
    "    dense_vectors = model.encode(texts_for_embedding)\n",
    "    sparse_vectors = bm25.raw_embed(texts_for_embedding)\n",
    "\n",
    "    points = []\n",
    "    for idx, (batch_idx, row) in enumerate(batch.iterrows()):\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"description\"]\n",
    "        price = row[\"price\"]\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=batch_idx,\n",
    "                vector={\n",
    "                    \"dense_vector\": dense_vectors[idx],\n",
    "                    \"sparse_vector\": sparse_vectors[idx],\n",
    "                },\n",
    "                payload={\n",
    "                    \"title\": title,\n",
    "                    \"description\": description,\n",
    "                    \"price\": price,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    operation_info = client.upsert(\n",
    "        collection_name=COLLECTION_NAME, wait=True, points=points\n",
    "    )\n",
    "    print(operation_info, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query_text: str):\n",
    "    dense_vector = model.encode([query_text])[0]\n",
    "    sparse_vector = bm25.raw_embed([query_text])[0]\n",
    "\n",
    "    prefetch = [\n",
    "        Prefetch(query=dense_vector, using=\"dense_vector\", limit=10),\n",
    "        Prefetch(query=SparseVector(**sparse_vector), using=\"sparse_vector\", limit=10),\n",
    "    ]\n",
    "\n",
    "    # results = client.query_points(\n",
    "    #     collection_name=COLLECTION_NAME,\n",
    "    #     prefetch=prefetch,\n",
    "    #     query=FusionQuery(fusion=Fusion.RRF),\n",
    "    #     with_payload=True,\n",
    "    #     limit=5,\n",
    "    # )\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=dense_vector,\n",
    "        using=\"dense_vector\",\n",
    "        with_payload=True,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    return [{\"score\": point.score, \"payload\": point.payload} for point in results.points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_result = query(\"small smartphone\")\n",
    "pprint(query_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
