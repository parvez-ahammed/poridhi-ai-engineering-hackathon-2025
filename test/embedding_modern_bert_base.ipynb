{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = os.getcwd() + \"/.cache/huggingface\"\n",
    "os.environ[\"HF_HOME\"] = PATH\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = PATH\n",
    "os.environ[\"TORCH_HOME\"] = PATH\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    PointStruct,\n",
    "    Distance,\n",
    "    VectorParams,\n",
    "    SparseVectorParams,\n",
    "    Modifier,\n",
    ")\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "from fastembed.sparse.bm25 import Bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/modernbert-embed-base-tokenizer\")\n",
    "model = AutoModel.from_pretrained(\"../models/modernbert-embed-base-model\")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "bm25_embed_model = Bm25(\"Qdrant/bm25\", cache_dir=os.path.join(os.pardir, \"bm25_cache\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "def dense_embedding(texts: list[str]):\n",
    "    encoded_queries = tokenizer(\n",
    "        texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        queries_outputs = model(**encoded_queries.to(DEVICE))\n",
    "\n",
    "    embeddings = mean_pooling(queries_outputs, encoded_queries[\"attention_mask\"])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "def sparse_embedding(texts: list[str]):\n",
    "    embedding = list(bm25_embed_model.passage_embed(texts))\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"product_collection_modern_bert_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(url=\"http://localhost:6333\", timeout=600)\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"modern_bert_base\": VectorParams(size=768, distance=Distance.COSINE)\n",
    "    },\n",
    "    sparse_vectors_config={\"bm25\": SparseVectorParams(modifier=Modifier.IDF)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_info_df = pd.read_csv(\"./final_5000_products.csv\")\n",
    "product_info_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_row = product_info_df.shape[0]\n",
    "batch_size = 1\n",
    "total_batch = math.ceil(total_row / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "progress_bar = tqdm(total=total_batch)\n",
    "cnt = 0\n",
    "\n",
    "while True:\n",
    "    end_idx = min(total_row, start_idx + batch_size)\n",
    "    # print(f\"{start_idx=} {end_idx=}\")\n",
    "\n",
    "    batch = product_info_df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    titles = batch[\"title\"].tolist()\n",
    "    descriptions = batch[\"description\"].tolist()\n",
    "    prices = batch[\"price\"].tolist()\n",
    "\n",
    "    texts_for_embedding = [f\"Title:{title} | Description: {description} | Price: {price}\" for title, description, price in zip(titles, descriptions, prices)]\n",
    "    dense_vectors = dense_embedding(texts_for_embedding)\n",
    "    sparse_vectors = sparse_embedding(texts_for_embedding)\n",
    "\n",
    "    \n",
    "    points = []\n",
    "    for idx, (batch_idx, row) in enumerate(batch.iterrows()):\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"description\"]\n",
    "        price = row[\"price\"]\n",
    "\n",
    "        points.append(\n",
    "            PointStruct(\n",
    "                id=batch_idx,\n",
    "                vector={\n",
    "                    \"modern_bert_base\": dense_vectors[idx],\n",
    "                    \"bm25\": sparse_vectors[idx].as_object()\n",
    "                },\n",
    "                payload={\n",
    "                    \"title\": title,\n",
    "                    \"description\": description,\n",
    "                    \"price\": price,\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "\n",
    "    operation_info = client.upsert(\n",
    "        collection_name=COLLECTION_NAME, wait=True, points=points\n",
    "    )\n",
    "    print(operation_info, end=\"\\r\")\n",
    "    progress_bar.update(1)\n",
    "\n",
    "    if end_idx >= total_row:\n",
    "        break\n",
    "\n",
    "    start_idx = end_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
